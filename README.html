<!DOCTYPE html><html><head>
      <title>README</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\86138\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.6.5\node_modules\@shd101wyy\mume\dependencies\katex\katex.min.css">
      
      
      
      
      
      
      
      
      
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="explorer">Explorer</h1>

<p>Explorer is a PyTorch reinforcement learning framework for <strong>exploring</strong> new ideas.</p>
<h2 class="mume-header" id="implemented-algorithms">Implemented algorithms</h2>

<ul>
<li>Vanilla Deep Q-learning (VanillaDQN): No target network.</li>
<li><a href="https://users.cs.duke.edu/~pdinesh/sources/MnihEtAlHassibis15NatureControlDeepRL.pdf">Deep Q-Learning (DQN)</a></li>
<li><a href="https://arxiv.org/pdf/1509.06461.pdf">Double Deep Q-learning (DDQN)</a></li>
<li><a href="https://arxiv.org/pdf/2002.06487.pdf">Maxmin Deep Q-learning (MaxminDQN)</a></li>
<li><a href="https://arxiv.org/pdf/1611.01929.pdf">Averaged Deep Q-learning (AveragedDQN)</a></li>
<li><a href="https://arxiv.org/pdf/1611.01929.pdf">Ensemble Deep Q-learning (EnsembleDQN)</a></li>
<li><a href="https://arxiv.org/pdf/1602.04621.pdf">Bootstrapped Deep Q-learning (BootstrappedDQN)</a></li>
<li><a href="https://arxiv.org/pdf/1706.10295.pdf">NoisyNet Deep Q-learning (NoisyNetDQN)</a></li>
<li><a href="http://incompleteideas.net/book/RLbook2020.pdf">REINFORCE</a></li>
<li><a href="http://incompleteideas.net/book/RLbook2020.pdf">Actor-Critic</a></li>
<li><a href="https://arxiv.org/pdf/1707.06347.pdf">Proximal Policy Optimisation (PPO)</a></li>
<li><a href="https://arxiv.org/pdf/1812.05905.pdf">Soft Actor-Critic (SAC)</a></li>
<li><a href="https://arxiv.org/pdf/1509.02971.pdf">Deep Deterministic Policy Gradients (DDPG)</a></li>
<li><a href="https://arxiv.org/pdf/1802.09477.pdf">Twin Delayed Deep Deterministic Policy Gradients (TD3)</a></li>
<li><a href="https://arxiv.org/pdf/2103.05147.pdf">Reward Policy Gradient (RPG)</a></li>
<li><a href="https://arxiv.org/pdf/2205.10868.pdf">Memory-efficient Deep Q-learning (MeDQN)</a></li>
</ul>
<h2 class="mume-header" id="to-do-list">To do list</h2>

<ul>
<li>SAC with automatically adjusted temperature</li>
<li>SAC with discrete action spaces</li>
</ul>
<h2 class="mume-header" id="the-dependency-tree-of-agent-classes">The dependency tree of agent classes</h2>

<pre class="language-text">Base Agent
  &#x251C;&#x2500;&#x2500; Vanilla DQN
  |     &#x251C;&#x2500;&#x2500; DQN
  |     |    &#x251C;&#x2500;&#x2500; DDQN
  |     |    &#x251C;&#x2500;&#x2500; NoisyNetDQN
  |     |    &#x251C;&#x2500;&#x2500; BootstrappedDQN
  |     |    &#x2514;&#x2500;&#x2500; MeDQN_Uniform, MeDQN_Real
  |     &#x251C;&#x2500;&#x2500; Maxmin DQN &#x2500;&#x2500; Ensemble DQN
  |     &#x2514;&#x2500;&#x2500; Averaged DQN
  &#x2514;&#x2500;&#x2500; REINFORCE 
        &#x251C;&#x2500;&#x2500; Actor-Critic
        |     &#x2514;&#x2500;&#x2500; PPO &#x2500;&#x2500; RPG
        &#x2514;&#x2500;&#x2500; SAC &#x2500;&#x2500; DDPG &#x2500;&#x2500; TD3
</pre>
<h2 class="mume-header" id="requirements">Requirements</h2>

<ul>
<li>Python (&gt;=3.6)</li>
<li><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://github.com/qlan3/gym-games">Gym &amp;&amp; Gym Games</a>: You may only install part of Gym (<code>classic_control, box2d</code>) by command <code>pip install &apos;gym[classic_control, box2d]&apos;</code>.</li>
<li>Optional:
<ul>
<li><a href="https://www.gymlibrary.ml/environments/atari/">Gym Atari</a>: <code>pip install gym[atari,accept-rom-license]</code></li>
<li><a href="https://www.gymlibrary.ml/environments/mujoco/">Gym Mujoco</a>:
<ul>
<li>Download MuJoCo version 1.50 from <a href="https://www.roboti.us/download.html">MuJoCo website</a>.</li>
<li>Unzip the downloaded <code>mjpro150</code> directory into <code>~/.mujoco/mjpro150</code>, and place the activation key (the <code>mjkey.txt</code> file downloaded from <a href="https://www.roboti.us/license.html">here</a>) at <code>~/.mujoco/mjkey.txt</code>.</li>
<li>Install <a href="https://github.com/openai/mujoco-py">mujoco-py</a>: <code>pip install &apos;mujoco-py&lt;1.50.2,&gt;=1.50.1&apos;</code></li>
<li>Install gym[mujoco]: <code>pip install gym[mujoco]</code></li>
</ul>
</li>
<li><a href="https://pybullet.org/">PyBullet</a>: <code>pip install pybullet</code></li>
<li><a href="https://github.com/denisyarats/dmc2gym">DeepMind Control Suite</a>: <code>pip install git+git://github.com/denisyarats/dmc2gym.git</code></li>
</ul>
</li>
<li>Others: Please check <code>requirements.txt</code>.</li>
</ul>
<h2 class="mume-header" id="experiments">Experiments</h2>

<h3 class="mume-header" id="train-test">Train &amp;&amp; Test</h3>

<p>All hyperparameters including parameters for grid search are stored in a configuration file in directory <code>configs</code>. To run an experiment, a configuration index is first used to generate a configuration dict corresponding to this specific configuration index. Then we run an experiment defined by this configuration dict. All results including log files are saved in directory <code>logs</code>. Please refer to the code for details.</p>
<p>For example, run the experiment with configuration file <code>RPG.json</code> and configuration index <code>1</code>:</p>
<p><code>python main.py --config_file ./configs/RPG.json --config_idx 1</code></p>
<p>The models are tested for one episode after every <code>test_per_episodes</code> training episodes which can be set in the configuration file.</p>
<h3>Grid Search (Optional)</h3>
<p>First, we calculate the number of total combinations in a configuration file (e.g. <code>RPG.json</code>):</p>
<p><code>python utils/sweeper.py</code></p>
<p>The output will be:</p>
<p><code>Number of total combinations in RPG.json: 12</code></p>
<p>Then we run through all configuration indexes from <code>1</code> to <code>12</code>. The simplest way is using a bash script:</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash"><span class="token keyword keyword-for">for</span> <span class="token for-or-select variable">index</span> <span class="token keyword keyword-in">in</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">..</span><span class="token number">12</span><span class="token punctuation">}</span>
<span class="token keyword keyword-do">do</span>
  python main.py --config_file ./configs/RPG.json --config_idx <span class="token variable">$index</span>
<span class="token keyword keyword-done">done</span>
</pre><p><a href="https://www.gnu.org/software/parallel/">Parallel</a> is usually a better choice to schedule a large number of jobs:</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash">parallel --eta --ungroup python main.py --config_file ./configs/RPG.json --config_idx <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">}</span> ::: <span class="token variable"><span class="token variable">$(</span><span class="token function">seq</span> <span class="token number">1</span> <span class="token number">12</span><span class="token variable">)</span></span>
</pre><p>Any configuration index that has the same remainder (divided by the number of total combinations) should have the same configuration dict. So for multiple runs, we just need to add the number of total combinations to the configuration index. For example, 5 runs for configuration index <code>1</code>:</p>
<pre data-role="codeBlock" data-info class="language-"><code>for index in 1 13 25 37 49
do
  python main.py --config_file ./configs/RPG.json --config_idx $index
done
</code></pre><p>Or a simpler way:</p>
<pre data-role="codeBlock" data-info class="language-"><code>parallel --eta --ungroup python main.py --config_file ./configs/RPG.json --config_idx {1} ::: $(seq 1 12 60)
</code></pre><h3>Analysis (Optional)</h3>
<p>To analyze the experimental results, just run:</p>
<p><code>python analysis.py</code></p>
<p>Inside <code>analysis.py</code>, <code>unfinished_index</code> will print out the configuration indexes of unfinished jobs based on the existence of the result file. <code>memory_info</code> will print out the memory usage information and generate a histogram to show the distribution of memory usages in directory <code>logs/RPG/0</code>. Similarly, <code>time_info</code> will print out the time information and generate a histogram to show the distribution of time in directory <code>logs/RPG/0</code>. Finally, <code>analyze</code> will generate <code>csv</code> files that store training and test results. Please check <code>analysis.py</code> for more details. More functions are available in <code>utils/plotter.py</code>.</p>
<p>Enjoy!</p>
<h2>Code of My Papers</h2>
<ul>
<li>
<p><strong>Qingfeng Lan</strong>, Yangchen Pan, Alona Fyshe, Martha White. <strong>Maxmin Q-learning: Controlling the Estimation Bias of Q-learning.</strong> ICLR, 2020. <strong>(Poster)</strong> <a href="https://openreview.net/pdf?id=Bkg0u3Etwr">[paper]</a> <a href="https://github.com/qlan3/Explorer/releases/tag/maxmin1.0">[code]</a></p>
</li>
<li>
<p><strong>Qingfeng Lan</strong>, Samuele Tosatto, Homayoon Farrahi, A. Rupam Mahmood. <strong>Model-free Policy Learning with Reward Gradients.</strong> AISTATS, 2022. <strong>(Poster)</strong> <a href="https://arxiv.org/pdf/2103.05147.pdf">[paper]</a> <a href="https://github.com/qlan3/Explorer/tree/RPG">[code]</a> <a href="https://github.com/homayoonfarrahi/rpg-ur5">[robot experiment code]</a></p>
</li>
<li>
<p><strong>Qingfeng Lan</strong>, Yangchen Pan, Jun Luo, A. Rupam Mahmood. <strong>Memory-efficient Reinforcement Learning with Knowledge Consolidation.</strong> Arxiv <a href="https://arxiv.org/pdf/2205.10868.pdf">[paper]</a> <a href="https://github.com/qlan3/Explorer/">[code]</a></p>
</li>
</ul>
<h2>Cite</h2>
<p>If you find this repo useful to your research, please cite my paper if related. Otherwise, please cite this repo:</p>
<pre data-role="codeBlock" data-info="bibtex" class="language-bibtex"><code>@misc{Explorer,
  author = {Lan, Qingfeng},
  title = {A PyTorch Reinforcement Learning Framework for Exploring New Ideas},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub Repository},
  howpublished = {\url{https://github.com/qlan3/Explorer}}
}
</code></pre><h1>Acknowledgements</h1>
<ul>
<li><a href="https://github.com/ShangtongZhang/DeepRL">DeepRL</a></li>
<li><a href="https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch">Deep Reinforcement Learning Algorithms with PyTorch</a></li>
<li><a href="https://github.com/muhammadzaheer/classic-control">Classic Control</a></li>
<li><a href="https://github.com/openai/spinningup">Spinning Up in Deep RL</a></li>
<li><a href="https://github.com/facebookresearch/RandomizedValueFunctions">Randomized Value functions</a></li>
<li><a href="https://github.com/Kaixhin/Rainbow">Rainbow</a></li>
</ul>

      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>